{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/SportAnalytics/data_with_zones.csv')\n",
    "\n",
    "# Desired features to train on\n",
    "features = ['opposingteamid', 'teamid', 'compiledgametime', 'eventname', 'manpowersituation', 'outcome', 'type', 'zone', 'sequence_id']\n",
    "le_features = ['le_opposingteamid', 'le_teamid', 'le_compiledgametime', 'le_eventname', 'le_manpowersituation', 'le_outcome', 'le_type', 'le_zone', 'le_sequence_id']\n",
    "\n",
    "# Target output\n",
    "target = 'xg'\n",
    "\n",
    "# Transform (encode) categorical features to numerical\n",
    "le = LabelEncoder()\n",
    "data['le_opposingteamid'] =  le.fit_transform(data['opposingteamid'])\n",
    "data['le_teamid'] =  le.fit_transform(data['teamid'])\n",
    "data['le_compiledgametime'] =  le.fit_transform(data['compiledgametime'])\n",
    "data['le_eventname'] =  le.fit_transform(data['eventname'])\n",
    "data['le_manpowersituation'] =  le.fit_transform(data['manpowersituation'])\n",
    "data['le_outcome'] =  le.fit_transform(data['outcome'])\n",
    "data['le_type'] =  le.fit_transform(data['type'])\n",
    "data['le_zone'] =  le.fit_transform(data['zone'])\n",
    "data['le_sequence_id'] =  le.fit_transform(data['sequence_id'])\n",
    "\n",
    "#print(data.loc[:, ['zone', 'le_zone']])\n",
    "\n",
    "features = le_features\n",
    "\n",
    "# Fill \"na\"-values with zeros in xg column\n",
    "data[target] = data[target].fillna(0)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Split data into train- and test data\n",
    "train, test = train_test_split(data[features + [target]], test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_data(data, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    start_indices = []\n",
    "    for i in range(len(data)):\n",
    "        # Check if i:th event is a shot\n",
    "        if data.iloc[i][target] > 0:\n",
    "            sequence_id = data.iloc[i]['le_sequence_id']\n",
    "            target_ = data.iloc[i][target]\n",
    "            \n",
    "            # Find the rows with the same sequence_id as the shot\n",
    "            sequence_indices = np.where(data['le_sequence_id'].values[:i] == sequence_id)[0]\n",
    "\n",
    "            # New sequence length (shortest of \"sequence_length\" and the available sequence)\n",
    "            seq_len = min(sequence_length, len(sequence_indices))\n",
    "\n",
    "            # Index of first event in sequence\n",
    "            start_index = sequence_indices[-seq_len]\n",
    "            start_indices.append(start_index)\n",
    "                \n",
    "            # One whole sequence from start_index to shot\n",
    "            sequence = data.iloc[start_index:i][features].values\n",
    "\n",
    "            #entries.append(entry)\n",
    "            sequences.append(sequence)\n",
    "            targets.append(target_)             \n",
    "    return np.array(sequences, dtype=object), np.array(targets), np.array(start_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of sequence before shot\n",
    "sequence_length = 100\n",
    "\n",
    "# Create train- and test sequences\n",
    "x_train_seq, y_train_seq, train_start_indices = sequence_data(train, sequence_length)\n",
    "x_test_seq, y_test_seq, test_start_indices = sequence_data(test, sequence_length)\n",
    "\n",
    "train_entries = data.iloc[train_start_indices]['le_eventname'].values\n",
    "test_entries = data.iloc[test_start_indices]['le_eventname'].values\n",
    "\n",
    "train_entry_count = Counter(train_entries)\n",
    "test_entry_count = Counter(test_entries)\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "x_train_seq = pad_sequences(x_train_seq, maxlen=sequence_length, dtype='float32')\n",
    "x_test_seq = pad_sequences(x_test_seq, maxlen=sequence_length, dtype='float32')\n",
    "\n",
    "# Convert the NumPy arrays to tensors\n",
    "x_train_seq = tf.convert_to_tensor(x_train_seq)\n",
    "y_train_seq = tf.convert_to_tensor(y_train_seq)\n",
    "x_test_seq = tf.convert_to_tensor(x_test_seq)\n",
    "y_test_seq = tf.convert_to_tensor(y_test_seq)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (sequence_length, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "fit_model = model.fit(x_train_seq, y_train_seq, epochs=100, batch_size=32, validation_data=(x_test_seq, y_test_seq), verbose=1)\n",
    "mse = model.evaluate(x_test_seq, y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(fit_model.history['loss'])\n",
    "plt.plot(fit_model.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 0.01)\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_seq)\n",
    "\n",
    "# Convert tensor to NumPy array and flatten\n",
    "y_test_seq_flat = y_test_seq.numpy().flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Remove some \"outliers\"\n",
    "mask = (y_test_seq_flat <= 0.6) & (y_pred_flat <= 0.6)\n",
    "y_test_out = y_test_seq_flat[mask]\n",
    "y_pred_out = y_pred_flat[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventnames\n",
    "unique_event_names = data['eventname'].unique()\n",
    "encoded_events = []\n",
    "\n",
    "for event_name in unique_event_names:\n",
    "    unique_le_event_names = data[data['eventname'] == event_name]['le_eventname'].unique()\n",
    "    for le_event_name in unique_le_event_names:\n",
    "        encoded_events.append(f\"{event_name}: {le_event_name}\")\n",
    "#print(encoded_events)\n",
    "\n",
    "decoded_names = []\n",
    "encoded_names = []\n",
    "\n",
    "for event in encoded_events:\n",
    "    event_name = event.split(\":\")[0]\n",
    "    decoded_names.append(event_name)\n",
    "\n",
    "for event in encoded_events:\n",
    "    event_name = event.split(\":\")[1]\n",
    "    encoded_names.append(event_name)\n",
    "\n",
    "\n",
    "# zone\n",
    "unique_zone_names = data['zone'].unique()\n",
    "encoded_zone_names = []\n",
    "\n",
    "for zone_name in unique_zone_names:\n",
    "    unique_le_zone_names = data[data['zone'] == zone_name]['le_zone'].unique()\n",
    "    for le_zone_name in unique_le_zone_names:\n",
    "        encoded_zone_names.append(f\"{zone_name}: {le_zone_name}\")\n",
    "\n",
    "decoded_zone = []\n",
    "encoded_zone = []\n",
    "\n",
    "for i in encoded_zone_names:\n",
    "    zone_name = i.split(\":\")[0]\n",
    "    decoded_zone.append(zone_name)\n",
    "\n",
    "for i in encoded_zone_names:\n",
    "    zone_name = i.split(\":\")[1]\n",
    "    encoded_zone.append(zone_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High xG sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "top_sequences = [] \n",
    "total_eventname_count = Counter()\n",
    "total_zone_count = Counter()\n",
    "\n",
    "# Iterate over the test set and find the sequences with the highest predicted xg values\n",
    "for i in range(len(y_pred)):\n",
    "    predicted_xg = y_pred[i]\n",
    "    sequence = x_test_seq[i]\n",
    "    top_sequences.append((predicted_xg, sequence))\n",
    "\n",
    "# Sort the list of top sequences based on predicted xg values in descending order\n",
    "top_sequences = sorted(top_sequences, reverse=True)\n",
    "\n",
    "# Get the top n sequences\n",
    "top_n_sequences = top_sequences[:n]\n",
    "\n",
    "zone_counter = 0\n",
    "name_counter = 0\n",
    "\n",
    "# Print the top n sequences\n",
    "for i in range(n):\n",
    "    final_eventname_list = [] # list of final eventnames\n",
    "    final_zone_list = []\n",
    "    sequence = top_n_sequences[i][1]\n",
    "    \n",
    "    for j in range(len(sequence)):\n",
    "        for k in range(len(encoded_names)):\n",
    "            if (str(sequence[:,3][j].numpy()) == '0.0'):\n",
    "                continue\n",
    "            if (str(sequence[:,3][j].numpy())[:-1] in encoded_names[k]):\n",
    "                final_eventname_list.append(decoded_names[k])\n",
    "                name_counter = name_counter + 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "        for k in range(len(encoded_zone)):\n",
    "            if (str(sequence[:,7][j].numpy()) == '0.0'):\n",
    "                continue\n",
    "            if (str(sequence[:,7][j].numpy())[:-1] in encoded_zone[k]):\n",
    "                final_zone_list.append(decoded_zone[k])\n",
    "                zone_counter = zone_counter + 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "    \n",
    "    # Print the sequence\n",
    "    #print(f\"Sequence with the {i+1} highest predicted xg: {final_zone_list}\")\n",
    "    \n",
    "    name_count = Counter(final_eventname_list)\n",
    "    zone_count = Counter(final_zone_list)\n",
    "    #print(name_count)\n",
    "    total_eventname_count.update(name_count)\n",
    "    total_zone_count.update(zone_count)\n",
    "\n",
    "#print(total_count)\n",
    "\n",
    "avg_eventname_count = {}\n",
    "for event, count in total_eventname_count.items():\n",
    "    avg_eventname_count[event] = count / n\n",
    "sorted_avg_count = dict(sorted(avg_eventname_count.items(), key=lambda item: item[1], reverse=True))\n",
    "#print(sorted_avg_count)\n",
    "\n",
    "\n",
    "avg_zone_count = {}\n",
    "for event, count in total_zone_count.items():\n",
    "    avg_zone_count[event] = count / n\n",
    "sorted_zone_count = dict(sorted(avg_zone_count.items(), key=lambda item: item[1], reverse=True))\n",
    "#print(sorted_zone_count)\n",
    "\n",
    "avg_name_len = name_counter/n\n",
    "print(avg_name_len)\n",
    "\n",
    "avg_zone_len = zone_counter/n\n",
    "print(avg_zone_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low xG sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "bottom_sequences = []\n",
    "total_count = Counter()\n",
    "total_zone_count = Counter()\n",
    "\n",
    "# Iterate over the test set and find the sequences with the lowest predicted xg values\n",
    "for i in range(len(y_pred)):\n",
    "    predicted_xg = y_pred[i]\n",
    "    sequence = x_test_seq[i]\n",
    "    bottom_sequences.append((predicted_xg, sequence))\n",
    "\n",
    "# Sort the list of top sequences based on predicted xg values in descending order\n",
    "bottom_sequences = sorted(bottom_sequences, reverse=False)\n",
    "\n",
    "# Get the top n sequences\n",
    "bottom_n_sequences = bottom_sequences[:n]\n",
    "\n",
    "zone_counter = 0\n",
    "name_counter = 0\n",
    "\n",
    "# Print the top n sequences\n",
    "for i in range(n):\n",
    "    final_list = [] # list of final eventnames\n",
    "    final_zone_list = []\n",
    "    sequence = bottom_n_sequences[i][1]\n",
    "    \n",
    "    for j in range(len(sequence)):\n",
    "        for k in range(len(encoded_names)):\n",
    "            if (str(sequence[:,3][j].numpy()) == '0.0'):\n",
    "                continue\n",
    "            if (str(sequence[:,3][j].numpy())[:-1] in encoded_names[k]):\n",
    "                final_list.append(decoded_names[k])\n",
    "                name_counter = name_counter + 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "        for k in range(len(encoded_zone)):\n",
    "            if (str(sequence[:,7][j].numpy()) == '0.0'):\n",
    "                continue\n",
    "            if (str(sequence[:,7][j].numpy())[:-1] in encoded_zone[k]):\n",
    "                final_zone_list.append(decoded_zone[k])\n",
    "                zone_counter = zone_counter + 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "            \n",
    "    # Print the sequence\n",
    "    #print(f\"Sequence with the {i+1} lowest predicted xg: {final_list}\")\n",
    "\n",
    "    name_count = Counter(final_list)\n",
    "    zone_count = Counter(final_zone_list)\n",
    "\n",
    "    #print(name_count)\n",
    "    total_count.update(name_count)\n",
    "    total_zone_count.update(zone_count)\n",
    "\n",
    "#print(total_count)\n",
    "\n",
    "avg_count = {}\n",
    "for event, count in total_count.items():\n",
    "    avg_count[event] = count / n\n",
    "sorted_avg_count = dict(sorted(avg_count.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_avg_count)\n",
    "\n",
    "avg_zone_count = {}\n",
    "for event, count in total_zone_count.items():\n",
    "    avg_zone_count[event] = count / n\n",
    "sorted_zone_count = dict(sorted(avg_zone_count.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_zone_count)\n",
    "\n",
    "avg_zone_len = zone_counter/n\n",
    "print(avg_zone_len)\n",
    "\n",
    "avg_name_len = name_counter/n\n",
    "print(avg_name_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot with the regression line\n",
    "plt.scatter(y_test_out, y_pred_out, color='green')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.xlim(0, 0.6)\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "# Regression line\n",
    "m, b = np.polyfit(y_test_out, y_pred_out, 1)\n",
    "plt.plot(y_test_out, m*y_test_out+b, color='red')\n",
    "plt.plot(y_test_out, y_test_out, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max predicted goal rate: {np.max(y_pred_out):.10f}\")\n",
    "print(f\"Min predicted goal rate: {np.min(y_pred_out):.10f}\")\n",
    "\n",
    "print(f\"Max test goal rate: {np.max(y_test_out):.10f}\")\n",
    "print(f\"Min test goal rate: {np.min(y_test_out):.10f}\")\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
  },
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
